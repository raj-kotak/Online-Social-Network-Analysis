Project Purpose:
    The goal of this project is to create a Clustering and Classification Model, using methodologies learnt in classroom. 
    The idea is to analyse the social network and trends and come-up with the model that acheive the purpose of assignment.

As given, the entire assignemnt is divided into 4 parts, as follows:
    Initaially for knowledge, The social network is analysed by collecting the tweets based on a keyword which is most trending. 
    I have collected tweets on "Cryptocurrency", which is quite a trending topic on social media.

collect.py:
    The key purpose of this file is to collect data using Twitter's REST API to search tweets, 
    I have collected 1000 tweets on keyword by filtering out the re-tweets in order to have a unique tweets. 
    Once the tweets have been collected it is stored in one tweets.txt file. 
    Now after that the tweets information is used to find the friends list of each of the screen_name of user, 
    thereby collecting friends of all 2000 tweets user's friends and stored in users_friends.txt. 
    Apart from that in order to perform classification based on sentiment of tweets, 
    I have used Afinn data which provides the prelabled words as negative and positive polarity. 
    Its fetched and stored in respective files for negative and positive.

cluster.py:
    The key purpose is to find and compute the communities based on similarity of users. 
    In order to perform clustering, I have read the tweets and each tweet user's friends which we have collected 
    during collect phase. 
    In order to find communities first I have created a graph nodes with all users, now to add an edge between nodes, 
    I have made an edge between two users. Now that graph is created, we need graph to be more densed and properly fit for clustering,
    so I have kept only those nodes which has a degree greater than 1 and removed rest. 
    Now to perform clustering I have used the girvan newman algorithm taught in class, by finding the connected components based on maximum centrality. 
    Once the cluster component is created its written into clusters.txt file.

classify.py:
    The key purpose of classification is to classify tweets based on positive and negative sentiments using machine learning. 
    The Model is trained using token features, also token pair features which takes a combination of pairs of closest word in the context, 
    also model is trained using lexicon features based on negative and positive words collected via Afinn. 
    Once the model is trained the collected tweets of 2000 users is used as a test data to predict the sentiment, 
    the analysis takes time to compute as training a model on large train data to have an efficient output of classification. 
    After the prediction on tweets as a test data the necessary information is written in the classifications.txt file to be used in the next stage of assignment.

summarize.py
    The key pupose of summarize is to give a summary of important factors in assignment, 
    it simply creates a file with necessary information by reading all different files we have stored in above stages of assignment.

Conclusion:
    After analysing the data in summary file we can say that more people having negative sentiments about Cryptocurrency, 
    while there are some people which are happy and making profits out of Cryptocurrency and having positive sentiment. 

Instructions to execute the assignment:
    Place the data folder in to the same location as all .py files, place all .txt files at same location as .py files.
    Then excute each .py files in order to have a correct output.
